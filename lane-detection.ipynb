{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import cv2\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect and convert image colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_rel(img, lo, hi):\n",
    "    vmin = np.min(img)\n",
    "    vmax = np.max(img)\n",
    "    \n",
    "    vlo = vmin + (vmax - vmin) * lo\n",
    "    vhi = vmin + (vmax - vmin) * hi\n",
    "    return np.uint8((img >= vlo) & (img <= vhi)) * 255\n",
    "\n",
    "def threshold_abs(img, lo, hi):\n",
    "    return np.uint8((img >= lo) & (img <= hi)) * 255\n",
    "\n",
    "\n",
    "def getHLSImage(img): \n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    h_channel = hls[:,:,0]\n",
    "    l_channel = hls[:,:,1]\n",
    "    s_channel = hls[:,:,2]\n",
    "    v_channel = hsv[:,:,2]\n",
    "\n",
    "    right_lane = threshold_rel(l_channel, 0.8, 1.0)\n",
    "    right_lane[:,:750] = 0\n",
    "\n",
    "    left_lane = threshold_abs(h_channel, 20, 30)\n",
    "    left_lane &= threshold_rel(v_channel, 0.7, 1.0)\n",
    "    left_lane[:,550:] = 0\n",
    "\n",
    "    finalImg = left_lane | right_lane\n",
    "    return finalImg\n",
    "\n",
    "\n",
    "def plotImage(img):\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Canny Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cannyEdgeDetection(img):\n",
    "    blurredImg = cv2.GaussianBlur(img, (5,5), 0)\n",
    "    cannyImg = cv2.Canny(blurredImg, 160 ,170)\n",
    "    return cannyImg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskImage(img):\n",
    "    height = img.shape[0]\n",
    "    width = img.shape[1]\n",
    "    regionOfInterest = [\n",
    "        (0, height),\n",
    "        (width/2, height/2),\n",
    "        (width, height)\n",
    "    ]\n",
    "    rectangle = np.array([regionOfInterest], np.int32)\n",
    "    mask = np.zeros_like(img)\n",
    "    # all pixels will be black\n",
    "    cv2.fillPoly(mask, rectangle, 255)\n",
    "\n",
    "    # plt.imshow(cv2.cvtColor(mask, cv2.COLOR_BGR2RGB))\n",
    "    maskedImage = cv2.bitwise_and(img, mask)\n",
    "    return maskedImage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perspective Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Assigning the source and destination points for the perspective transform \"\"\"\n",
    "# coordinates = [x, y]\n",
    "top_left = [510, 480]\n",
    "top_right = [780, 480]\n",
    "bottom_left = [270, 690]\n",
    "bottom_right = [1230, 690]\n",
    "\n",
    "\n",
    "srcPoints = np.array([\n",
    "    top_left,\n",
    "    top_right,\n",
    "    bottom_left,\n",
    "    bottom_right,\n",
    "\n",
    "]).astype(np.float32)\n",
    "\n",
    "dstPoints = np.array([\n",
    "    [0, 0],\n",
    "    [550, 0],\n",
    "    [0, 350],\n",
    "    [550, 350],\n",
    "]).astype(np.float32)\n",
    "\n",
    "warpedImgSize = (550, 350) # (width, height) for transformed image\n",
    "\n",
    "''' Perspective transform functions for the lane detection '''\n",
    "def perspectiveTransform(srcPoints, dstPoints):\n",
    "    M = cv2.getPerspectiveTransform(srcPoints, dstPoints)\n",
    "    Minv = cv2.getPerspectiveTransform(dstPoints, srcPoints)\n",
    "    return M, Minv\n",
    "\n",
    "\n",
    "def warpPerspective(img, imgSize, M):\n",
    "    return cv2.warpPerspective(img, M, imgSize, cv2.INTER_LINEAR)\n",
    "\n",
    "\n",
    "def transformImage(img, source, destination, imgSize):\n",
    "    \"\"\" transform the image to bird's eye view \"\"\"\n",
    "\n",
    "    M, Minv = perspectiveTransform(source, destination)\n",
    "    warpedImg = warpPerspective(img, imgSize, M)\n",
    "    # plotImage(warpedImg)\n",
    "    return warpedImg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = imageio.get_reader('/content/drive/My Drive/challenge_video.mp4', 'ffmpeg')\n",
    "finalVid = imageio.get_writer('/content/drive/My Drive/output_challenge_video.mp4', fps = 30)\n",
    "\n",
    "for i, img in enumerate(vid):\n",
    "    HLSImg = getHLSImage(img)\n",
    "    cannyImg = cannyEdgeDetection(HLSImg)\n",
    "    maskedImage = maskImage(cannyImg)\n",
    "    finalVid.append_data(maskedImage)\n",
    "\n",
    "\n",
    "finalVid.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
