{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from typing import Optional, List, Tuple\n",
    "import imageio\n",
    "import cv2\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect and convert image colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_rel(img, lo, hi):\n",
    "    vmin = np.min(img)\n",
    "    vmax = np.max(img)\n",
    "    \n",
    "    vlo = vmin + (vmax - vmin) * lo\n",
    "    vhi = vmin + (vmax - vmin) * hi\n",
    "    return np.uint8((img >= vlo) & (img <= vhi)) * 255\n",
    "\n",
    "def threshold_abs(img, lo, hi):\n",
    "    return np.uint8((img >= lo) & (img <= hi)) * 255\n",
    "\n",
    "\n",
    "def getHLSImage(img): \n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    h_channel = hls[:,:,0]\n",
    "    l_channel = hls[:,:,1]\n",
    "    s_channel = hls[:,:,2]\n",
    "    v_channel = hsv[:,:,2]\n",
    "\n",
    "    right_lane = threshold_rel(l_channel, 0.8, 1.0)\n",
    "    right_lane[:,:750] = 0\n",
    "\n",
    "    left_lane = threshold_abs(h_channel, 20, 30)\n",
    "    left_lane &= threshold_rel(v_channel, 0.7, 1.0)\n",
    "    left_lane[:,550:] = 0\n",
    "\n",
    "    finalImg = left_lane | right_lane\n",
    "    return finalImg\n",
    "\n",
    "\n",
    "def plotImage(img):\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Canny Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h1 = 100\n",
    "# h2 = 200\n",
    "def cannyEdgeDetection(img, h1 = 160, h2= 170):\n",
    "    blurredImg = cv2.GaussianBlur(img, (5,5), 0)\n",
    "    cannyImg = cv2.Canny(blurredImg, h1 ,h2)\n",
    "    return cannyImg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regionOfInterest(img, color):\n",
    "    height = img.shape[0]\n",
    "    width = img.shape[1]\n",
    "    regionOfInterest = [\n",
    "        (0, height),\n",
    "        (width/2, height/2),\n",
    "        (width, height)\n",
    "    ]\n",
    "    rectangle = np.array([regionOfInterest], np.int32)\n",
    "    mask = np.zeros_like(img)\n",
    "    # all pixels will be black\n",
    "    cv2.fillPoly(mask, rectangle, color)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskImage(img):\n",
    "    mask = regionOfInterest(img, 255)\n",
    "    # plt.imshow(cv2.cvtColor(mask, cv2.COLOR_BGR2RGB))\n",
    "    maskedImage = cv2.bitwise_and(img, mask)\n",
    "    return maskedImage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perspective Transform\n",
    "Applying transform to the image to see it in the bird's eye view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Assigning the source and destination points for the perspective transform \"\"\"\n",
    "# coordinates = [x, y]\n",
    "top_left = [510, 480]\n",
    "top_right = [780, 480]\n",
    "bottom_left = [270, 690]\n",
    "bottom_right = [1230, 690]\n",
    "\n",
    "\n",
    "srcPoints = np.array([\n",
    "    top_left,\n",
    "    top_right,\n",
    "    bottom_left,\n",
    "    bottom_right,\n",
    "\n",
    "]).astype(np.float32)\n",
    "\n",
    "dstPoints = np.array([\n",
    "    [0, 0],\n",
    "    [550, 0],\n",
    "    [0, 350],\n",
    "    [550, 350],\n",
    "]).astype(np.float32)\n",
    "\n",
    "warpedImgSize = (550, 350) # (width, height) for transformed image\n",
    "\n",
    "''' Perspective transform functions for the lane detection '''\n",
    "def perspectiveTransform(srcPoints, dstPoints):\n",
    "    M = cv2.getPerspectiveTransform(srcPoints, dstPoints)\n",
    "    Minv = cv2.getPerspectiveTransform(dstPoints, srcPoints)\n",
    "    return M, Minv\n",
    "\n",
    "\n",
    "def warpPerspective(img, imgSize, M):\n",
    "    return cv2.warpPerspective(img, M, imgSize, cv2.INTER_LINEAR)\n",
    "\n",
    "\n",
    "def transformImage(img, source, destination, imgSize):\n",
    "    \"\"\" transform the image to bird's eye view \"\"\"\n",
    "\n",
    "    M, Minv = perspectiveTransform(source, destination)\n",
    "    warpedImg = warpPerspective(img, imgSize, M)\n",
    "    # plotImage(warpedImg)\n",
    "    return warpedImg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hough Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPoints(I,numPts):\n",
    "    \"\"\" manually select points\"\"\"\n",
    "    %matplotlib\n",
    "    fig,ax = plt.subplots(1,figsize=(15,30))\n",
    "    plt.imshow(I,cmap='gray')\n",
    "    pts = np.round(np.array(plt.ginput(n=numPts)))\n",
    "    pts = pts[:,[1,0]].T\n",
    "    plt.close()\n",
    "    return pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def hough_lines(\n",
    "    img:np.ndarray,\n",
    "    rho: Optional[int] = 2,\n",
    "    theta: Optional[float] = np.pi/180,\n",
    "    threshold : Optional[int] = 50,\n",
    "    min_line_len: Optional[int] = 5,\n",
    "    max_line_gap: Optional[int] = 5)\\\n",
    "        -> List[np.ndarray]:\n",
    "    \"\"\"\n",
    "    takes in an image and returns its hough lines\n",
    "\n",
    "    Args:\n",
    "    -------\n",
    "        img (numpy.ndarray): an image\n",
    "        rho (int): the resolution of the rho axis\n",
    "        theta (float): the resolution of the theta axis\n",
    "        threshold (int): the minimum number of votes a line needs to be considered\n",
    "        min_line_len (int): the minimum length of a line\n",
    "        max_line_gap (int): the maximum gap between two lines\n",
    "\n",
    "    Returns:\n",
    "    ---------\n",
    "    A list of hough lines\n",
    "    \n",
    "    \"\"\"\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    return lines\n",
    "\n",
    "def draw_lines(\n",
    "        img: np.ndarray,\n",
    "        lines: np.ndarray,\n",
    "        color:Optional[Tuple[int,int,int]]=[0, 255, 0]\n",
    "        , thickness: Optional[int]=3)\\\n",
    "            -> np.ndarray:\n",
    "    \"\"\"\n",
    "    takes in an image and returns an image with the lines drawn on an empty image\n",
    "\n",
    "    Args:\n",
    "    -------\n",
    "        img (numpy.ndarray): an image\n",
    "        lines (numpy.ndarray): a list of hough lines\n",
    "        color (Tuple[int,int,int]): the color of the lines\n",
    "        thickness (int): the thickness of the lines\n",
    "\n",
    "    Returns:\n",
    "    ---------\n",
    "    An image with the lines drawn on it\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    line_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "    if lines is not None:\n",
    "        [\n",
    "            [\n",
    "                cv2.line(line_img, (x1, y1), (x2, y2), color, thickness)\n",
    "                for x1, y1, x2, y2 in line\n",
    "            ]\n",
    "            for line in lines\n",
    "        ]\n",
    "    return line_img\n",
    "\n",
    "def hough_image(\n",
    "    img: np.ndarray\n",
    "    ,img_hough: np.ndarray)\\\n",
    "        -> np.ndarray:\n",
    "    \"\"\"\n",
    "    takes in an image and its lines and returns it with the hough lines drawn on it\n",
    "\n",
    "    Args:\n",
    "    -------\n",
    "        img (numpy.ndarray): an image\n",
    "        img_hough (numpy.ndarray): an image with the hough lines drawn on it\n",
    "\n",
    "    Returns:\n",
    "    ---------\n",
    "    An image with the hough lines drawn on it\n",
    "    \n",
    "    \"\"\"\n",
    "    return cv2.addWeighted(img, 0.8, img_hough, 1, 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video Handlers: one to read input video and other for generating output video\n",
    "vid = imageio.get_reader('../../videos/project_video.mp4', 'ffmpeg')\n",
    "finalVid = imageio.get_writer('./output_project_video3.mp4', fps = 30)\n",
    "\n",
    "for i, img in enumerate(vid):\n",
    "    # Applying filters to the image\n",
    "    HLSImg = getHLSImage(img)\n",
    "    # print(HLSImg.shape)\n",
    "    cannyImg = cannyEdgeDetection(HLSImg)\n",
    "    maskedImage = maskImage(cannyImg)\n",
    "    transformedImage = transformImage(maskedImage, srcPoints, dstPoints, warpedImgSize)\n",
    "    # plt.imshow(transformedImage)\n",
    "    lines = hough_lines(img=transformedImage)\n",
    "    # print(lines)\n",
    "    # plt.imshow(lines)\n",
    "    lineImg = draw_lines(HLSImg, lines)\n",
    "    warpedImgSize = (1280, 720)\n",
    "    lineTransformedImage = transformImage(lineImg, dstPoints, srcPoints, warpedImgSize)\n",
    "    # print(lineTransformedImage.shape)\n",
    "    houghImage = hough_image(img, lineTransformedImage)\n",
    "    # result = cv2.addWeighted(img, 1, mask, 0.2, 0)\n",
    "\n",
    "    \n",
    "    # Appending final image to the video\n",
    "    finalVid.append_data(houghImage)\n",
    "\n",
    "\n",
    "finalVid.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
