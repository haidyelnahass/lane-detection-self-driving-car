{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from typing import Optional, List, Tuple\n",
    "import imageio\n",
    "import cv2\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect and convert image colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_rel(img, lo, hi):\n",
    "    vmin = np.min(img)\n",
    "    vmax = np.max(img)\n",
    "    \n",
    "    vlo = vmin + (vmax - vmin) * lo\n",
    "    vhi = vmin + (vmax - vmin) * hi\n",
    "    return np.uint8((img >= vlo) & (img <= vhi)) * 255\n",
    "\n",
    "def threshold_abs(img, lo, hi):\n",
    "    return np.uint8((img >= lo) & (img <= hi)) * 255\n",
    "\n",
    "\n",
    "def getHLSImage(img): \n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    h_channel = hls[:,:,0]\n",
    "    l_channel = hls[:,:,1]\n",
    "    s_channel = hls[:,:,2]\n",
    "    v_channel = hsv[:,:,2]\n",
    "\n",
    "    right_lane = threshold_rel(l_channel, 0.8, 1.0)\n",
    "    right_lane[:,:750] = 0\n",
    "\n",
    "    left_lane = threshold_abs(h_channel, 20, 30)\n",
    "    left_lane &= threshold_rel(v_channel, 0.7, 1.0)\n",
    "    left_lane[:,550:] = 0\n",
    "\n",
    "    finalImg = left_lane | right_lane\n",
    "    return finalImg\n",
    "\n",
    "\n",
    "def plotImage(img):\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Canny Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h1 = 100\n",
    "# h2 = 200\n",
    "def cannyEdgeDetection(img, h1 = 160, h2= 170):\n",
    "    blurredImg = cv2.GaussianBlur(img, (5,5), 0)\n",
    "    cannyImg = cv2.Canny(blurredImg, h1 ,h2)\n",
    "    return cannyImg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regionOfInterest(img, color):\n",
    "    height = img.shape[0]\n",
    "    width = img.shape[1]\n",
    "    regionOfInterest = [\n",
    "        (0, height),\n",
    "        (width/2, height/2),\n",
    "        (width, height)\n",
    "    ]\n",
    "    rectangle = np.array([regionOfInterest], np.int32)\n",
    "    mask = np.zeros_like(img)\n",
    "    # all pixels will be black\n",
    "    cv2.fillPoly(mask, rectangle, color)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskImage(img):\n",
    "    mask = regionOfInterest(img, 255)\n",
    "    # plt.imshow(cv2.cvtColor(mask, cv2.COLOR_BGR2RGB))\n",
    "    maskedImage = cv2.bitwise_and(img, mask)\n",
    "    return maskedImage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perspective Transform\n",
    "Applying transform to the image to see it in the bird's eye view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Assigning the source and destination points for the perspective transform \"\"\"\n",
    "# coordinates = [x, y]\n",
    "top_left = [510, 480]\n",
    "top_right = [780, 480]\n",
    "bottom_left = [270, 690]\n",
    "bottom_right = [1230, 690]\n",
    "\n",
    "\n",
    "srcPoints = np.array([\n",
    "    top_left,\n",
    "    top_right,\n",
    "    bottom_left,\n",
    "    bottom_right,\n",
    "\n",
    "]).astype(np.float32)\n",
    "\n",
    "dstPoints = np.array([\n",
    "    [0, 0],\n",
    "    [550, 0],\n",
    "    [0, 350],\n",
    "    [550, 350],\n",
    "]).astype(np.float32)\n",
    "\n",
    "warpedImgSize = (550, 350) # (width, height) for transformed image\n",
    "\n",
    "''' Perspective transform functions for the lane detection '''\n",
    "def perspectiveTransform(srcPoints, dstPoints):\n",
    "    M = cv2.getPerspectiveTransform(srcPoints, dstPoints)\n",
    "    Minv = cv2.getPerspectiveTransform(dstPoints, srcPoints)\n",
    "    return M, Minv\n",
    "\n",
    "\n",
    "def warpPerspective(img, imgSize, M):\n",
    "    return cv2.warpPerspective(img, M, imgSize, cv2.INTER_LINEAR)\n",
    "\n",
    "\n",
    "def transformImage(img, source, destination, imgSize):\n",
    "    \"\"\" transform the image to bird's eye view \"\"\"\n",
    "\n",
    "    M, Minv = perspectiveTransform(source, destination)\n",
    "    warpedImg = warpPerspective(img, imgSize, M)\n",
    "    # plotImage(warpedImg)\n",
    "    return warpedImg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hough Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPoints(I,numPts):\n",
    "    \"\"\" manually select points\"\"\"\n",
    "    %matplotlib\n",
    "    fig,ax = plt.subplots(1,figsize=(15,30))\n",
    "    plt.imshow(I,cmap='gray')\n",
    "    pts = np.round(np.array(plt.ginput(n=numPts)))\n",
    "    pts = pts[:,[1,0]].T\n",
    "    plt.close()\n",
    "    return pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def hough_lines(\n",
    "    img:np.ndarray,\n",
    "    rho: Optional[int] = 2,\n",
    "    theta: Optional[float] = np.pi/180,\n",
    "    threshold : Optional[int] = 50,\n",
    "    min_line_len: Optional[int] = 5,\n",
    "    max_line_gap: Optional[int] = 5)\\\n",
    "        -> List[np.ndarray]:\n",
    "    \"\"\"\n",
    "    takes in an image and returns its hough lines\n",
    "\n",
    "    Args:\n",
    "    -------\n",
    "        img (numpy.ndarray): an image\n",
    "        rho (int): the resolution of the rho axis\n",
    "        theta (float): the resolution of the theta axis\n",
    "        threshold (int): the minimum number of votes a line needs to be considered\n",
    "        min_line_len (int): the minimum length of a line\n",
    "        max_line_gap (int): the maximum gap between two lines\n",
    "\n",
    "    Returns:\n",
    "    ---------\n",
    "    A list of hough lines\n",
    "    \n",
    "    \"\"\"\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    return lines\n",
    "\n",
    "def draw_lines(\n",
    "        img: np.ndarray,\n",
    "        lines: np.ndarray,\n",
    "        color:Optional[Tuple[int,int,int]]=[0, 255, 0]\n",
    "        , thickness: Optional[int]=3)\\\n",
    "            -> np.ndarray:\n",
    "    \"\"\"\n",
    "    takes in an image and returns an image with the lines drawn on an empty image\n",
    "\n",
    "    Args:\n",
    "    -------\n",
    "        img (numpy.ndarray): an image\n",
    "        lines (numpy.ndarray): a list of hough lines\n",
    "        color (Tuple[int,int,int]): the color of the lines\n",
    "        thickness (int): the thickness of the lines\n",
    "\n",
    "    Returns:\n",
    "    ---------\n",
    "    An image with the lines drawn on it\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    line_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "    if lines is not None:\n",
    "        [\n",
    "            [\n",
    "                cv2.line(line_img, (x1, y1), (x2, y2), color, thickness)\n",
    "                for x1, y1, x2, y2 in line\n",
    "            ]\n",
    "            for line in lines\n",
    "        ]\n",
    "    return line_img\n",
    "\n",
    "def hough_image(\n",
    "    img: np.ndarray\n",
    "    ,img_hough: np.ndarray)\\\n",
    "        -> np.ndarray:\n",
    "    \"\"\"\n",
    "    takes in an image and its lines and returns it with the hough lines drawn on it\n",
    "\n",
    "    Args:\n",
    "    -------\n",
    "        img (numpy.ndarray): an image\n",
    "        img_hough (numpy.ndarray): an image with the hough lines drawn on it\n",
    "\n",
    "    Returns:\n",
    "    ---------\n",
    "    An image with the hough lines drawn on it\n",
    "    \n",
    "    \"\"\"\n",
    "    return cv2.addWeighted(img, 0.8, img_hough, 1, 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlayImage(bgImage, overlayImage, xOffset, yOffset, scaling):\n",
    "    scalingPercentage = scaling\n",
    "    width = int(overlayImage.shape[1] * scalingPercentage / 100)\n",
    "    height = int(overlayImage.shape[0] * scalingPercentage / 100)\n",
    "    dsize = (width, height)\n",
    "    resizedOverlay = cv2.resize(overlayImage, dsize)\n",
    "    stackedOverlay = np.zeros_like(resizedOverlay, shape = (resizedOverlay.shape[0],resizedOverlay.shape[1],3))\n",
    "    stackedOverlay[:,:,0] = resizedOverlay\n",
    "    stackedOverlay[:,:,1] = resizedOverlay\n",
    "    stackedOverlay[:,:,2] = resizedOverlay\n",
    "    # overlay image on top of original image\n",
    "\n",
    "    bgImage[yOffset:yOffset+stackedOverlay.shape[0], xOffset:xOffset+stackedOverlay.shape[1]] = stackedOverlay\n",
    "    return bgImage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sliding Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slidingWindow(img_w):\n",
    "\n",
    "    histogram = np.sum(img_w[int(img_w.shape[0] / 2):, :], axis=0)\n",
    "    # Create an output image to draw on and visualize the result\n",
    "    out_img = np.dstack((img_w, img_w, img_w)) * 255\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = int(histogram.shape[0] / 2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set height of windows\n",
    "    window_height = int(img_w.shape[0] / nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = img_w.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated for each window\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "      \n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = img_w.shape[0] - (window + 1) * window_height\n",
    "        win_y_high = img_w.shape[0] - window * window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img, (win_xleft_low, win_y_low), (win_xleft_high, win_y_high), (0, 255, 0), 2)\n",
    "        cv2.rectangle(out_img, (win_xright_low, win_y_low), (win_xright_high, win_y_high), (0, 255, 0), 2)\n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (\n",
    "            nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (\n",
    "            nonzerox < win_xright_high)).nonzero()[0]\n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "          \n",
    "          leftx_current = int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:\n",
    "          \n",
    "          rightx_current = int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds]\n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "    # Generate x and y values for plotting\n",
    "    # ploty = np.linspace(0, img_w.shape[0] - 1, img_w.shape[0])\n",
    "    # left_fitx = left_fit[0] * ploty ** 2 + left_fit[1] * ploty + left_fit[2]\n",
    "    # right_fitx = right_fit[0] * ploty ** 2 + right_fit[1] * ploty + right_fit[2]\n",
    "    #\n",
    "    # out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    # out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "    # plt.imshow(out_img)\n",
    "    # plt.plot(left_fitx, ploty, color='yellow')\n",
    "    # plt.plot(right_fitx, ploty, color='yellow')\n",
    "    # plt.xlim(0, 1280)\n",
    "    # plt.ylim(720, 0)\n",
    "\n",
    "    return left_fit, right_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitFromLines(left_fit, right_fit, img_w):\n",
    "    # Assume you now have a new warped binary image\n",
    "    # from the next frame of video (also called \"binary_warped\")\n",
    "    # It's now much easier to find line pixels!\n",
    "    nonzero = img_w.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    margin = 100\n",
    "    left_lane_inds = ((nonzerox > (left_fit[0] * (nonzeroy ** 2) + left_fit[1] * nonzeroy + left_fit[2] - margin)) & (\n",
    "    nonzerox < (left_fit[0] * (nonzeroy ** 2) + left_fit[1] * nonzeroy + left_fit[2] + margin)))\n",
    "    right_lane_inds = (\n",
    "    (nonzerox > (right_fit[0] * (nonzeroy ** 2) + right_fit[1] * nonzeroy + right_fit[2] - margin)) & (\n",
    "    nonzerox < (right_fit[0] * (nonzeroy ** 2) + right_fit[1] * nonzeroy + right_fit[2] + margin)))\n",
    "\n",
    "    # Again, extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds]\n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "    return left_fit, right_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw Lines on Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_lines(img, img_w, left_fit, right_fit, perspective):\n",
    "    # Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(img_w).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "    #color_warp_center = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "    ploty = np.linspace(0, img.shape[0] - 1, img.shape[0])\n",
    "\n",
    "    left_fitx = left_fit[0] * ploty ** 2 + left_fit[1] * ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0] * ploty ** 2 + right_fit[1] * ploty + right_fit[2]\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    #cv2.fillPoly(color_warp_center, np.int_([pts]), (0, 255, 0))\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0, 255, 0))\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = transformImage(color_warp, perspective[1], perspective[0], (1280,720))\n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(img, 1, newwarp, 0.2, 0)\n",
    "\n",
    "    color_warp_lines = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "    cv2.polylines(color_warp_lines, np.int_([pts_right]), isClosed=False, color=(255, 255, 0), thickness=25)\n",
    "    cv2.polylines(color_warp_lines, np.int_([pts_left]), isClosed=False, color=(0, 0, 255), thickness=25)\n",
    "    newwarp_lines = transformImage(color_warp_lines, perspective[1], perspective[0], (1280,720))\n",
    "\n",
    "    result = cv2.addWeighted(result, 1, newwarp_lines, 1, 0)\n",
    "\n",
    "    # ----- Radius Calculation ------ #\n",
    "\n",
    "    img_height = img.shape[0]\n",
    "    y_eval = img_height\n",
    "\n",
    "    ym_per_pix = 30 / 720.  # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7 / 700  # meters per pixel in x dimension\n",
    "\n",
    "    ploty = np.linspace(0, img_height - 1, img_height)\n",
    "    # Fit new polynomials to x,y in world space\n",
    "    left_fit_cr = np.polyfit(ploty * ym_per_pix, left_fitx * xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(ploty * ym_per_pix, right_fitx * xm_per_pix, 2)\n",
    "\n",
    "    # Calculate the new radii of curvature\n",
    "    left_curverad = ((1 + (2 * left_fit_cr[0] * y_eval * ym_per_pix + left_fit_cr[1]) ** 2) ** 1.5) / np.absolute(\n",
    "        2 * left_fit_cr[0])\n",
    "\n",
    "    right_curverad = (\n",
    "                         (1 + (2 * right_fit_cr[0] * y_eval * ym_per_pix + right_fit_cr[1]) ** 2) ** 1.5) / np.absolute(\n",
    "        2 * right_fit_cr[0])\n",
    "\n",
    "    radius = round((float(left_curverad) + float(right_curverad))/2.,2)\n",
    "\n",
    "    # ----- Off Center Calculation ------ #\n",
    "\n",
    "    lane_width = (right_fit[2] - left_fit[2]) * xm_per_pix\n",
    "    center = (right_fit[2] - left_fit[2]) / 2\n",
    "    off_left = (center - left_fit[2]) * xm_per_pix\n",
    "    off_right = -(right_fit[2] - center) * xm_per_pix\n",
    "    off_center = round((center - img.shape[0] / 2.) * xm_per_pix,2)\n",
    "\n",
    "    # --- Print text on screen ------ #\n",
    "    #if radius < 5000.0:\n",
    "    text = \"radius = %s [m]\\noffcenter = %s [m]\" % (str(radius), str(off_center))\n",
    "    #text = \"radius = -- [m]\\noffcenter = %s [m]\" % (str(off_center))\n",
    "\n",
    "    for i, line in enumerate(text.split('\\n')):\n",
    "        i = 800 + 20 * i\n",
    "        cv2.putText(result, line, (0,i), cv2.FONT_HERSHEY_DUPLEX, 0.5,(255,255,255),1,cv2.LINE_AA)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculare_center_distance(img, left_fit, right_fit):\n",
    "    CAR_DEFAULT_WIDTH_IN_CM = 180\n",
    "    pixelWidthInCm = CAR_DEFAULT_WIDTH_IN_CM/img.shape[1]\n",
    "    midPointOfLanes = (right_fit[2]+left_fit[2])/2\n",
    "    carCenter = img.shape[0]/2\n",
    "    distance = pixelWidthInCm*(abs(carCenter-midPointOfLanes))\n",
    "    distanceInM = str(round(distance/100, 4))\n",
    "    return distanceInM\n",
    "\n",
    "def calc_radius(img, left_fit, right_fit):\n",
    "    ploty = np.linspace(0, img.shape[0] - 1, img.shape[0])\n",
    "    left_fitx = left_fit[0] * ploty ** 2 + left_fit[1] * ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0] * ploty ** 2 + right_fit[1] * ploty + right_fit[2]\n",
    "\n",
    "    img_height = img.shape[0]\n",
    "    y_eval = img_height\n",
    "\n",
    "    ym_per_pix = 30 / 720.  # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7 / 700  # meters per pixel in x dimension\n",
    "\n",
    "    ploty = np.linspace(0, img_height - 1, img_height)\n",
    "    # Fit new polynomials to x,y in world space\n",
    "    left_fit_cr = np.polyfit(ploty * ym_per_pix, left_fitx * xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(ploty * ym_per_pix, right_fitx * xm_per_pix, 2)\n",
    "\n",
    "    # Calculate the new radii of curvature\n",
    "    left_curverad = ((1 + (2 * left_fit_cr[0] * y_eval * ym_per_pix + left_fit_cr[1]) ** 2) ** 1.5) / np.absolute(\n",
    "        2 * left_fit_cr[0])\n",
    "\n",
    "    right_curverad = (\n",
    "                         (1 + (2 * right_fit_cr[0] * y_eval * ym_per_pix + right_fit_cr[1]) ** 2) ** 1.5) / np.absolute(\n",
    "        2 * right_fit_cr[0])\n",
    "\n",
    "    return round((float(left_curverad) + float(right_curverad))/2.,2) \n",
    "    \n",
    "def draw_text_on_photo(img, text):\n",
    "    result = img\n",
    "    for i, line in enumerate(text.split('\\n')):\n",
    "        i = 50 + 20 * i\n",
    "        cv2.putText(result, line, (0, i), cv2.FONT_HERSHEY_DUPLEX,\n",
    "                    0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = imageio.get_reader('./project_video.mp4', 'ffmpeg')\n",
    "finalVid = imageio.get_writer('./output_challenge_videoooo.mp4', fps = 30)\n",
    "# img = cv2.imread('./road2.png')\n",
    "\n",
    "MOV_AVG_LENGTH = 5\n",
    "# planVideo = imageio.get_writer('./assets/plan_view_project_video.mp4', fps = 30)\n",
    "for i, img in enumerate(vid):\n",
    "  \n",
    "    HLSImg = getHLSImage(img)\n",
    "    cannyImg = cannyEdgeDetection(HLSImg)\n",
    "    maskedImage = maskImage(cannyImg)\n",
    "    transformedImage = transformImage(maskedImage, srcPoints, dstPoints, (550,350))\n",
    "    # img = overlayImage(img, maskedImage, 450, 20, 30) \n",
    "    # Here we are saving the transformed image to the video\n",
    "    # WARNING NOTE: operation takes time, so run one you need at a time\n",
    "    # ----------- Testing, comment from here -----------------\n",
    "\n",
    "    try:\n",
    "      \n",
    "      left_fit, right_fit = fitFromLines(left_fit, right_fit, transformedImage)\n",
    "\n",
    "      mov_avg_left = np.append(mov_avg_left,np.array([left_fit]), axis=0)\n",
    "      mov_avg_right = np.append(mov_avg_right,np.array([right_fit]), axis=0)\n",
    "\n",
    "    except:\n",
    "      try:\n",
    "        left_fit, right_fit = slidingWindow(transformedImage)\n",
    "        mov_avg_left = np.array([left_fit])\n",
    "        mov_avg_right = np.array([right_fit])\n",
    "      except:\n",
    "        pass\n",
    "\n",
    "    left_fit = np.array([np.mean(mov_avg_left[::-1][:,0][0:MOV_AVG_LENGTH]),\n",
    "                             np.mean(mov_avg_left[::-1][:,1][0:MOV_AVG_LENGTH]),\n",
    "                             np.mean(mov_avg_left[::-1][:,2][0:MOV_AVG_LENGTH])])\n",
    "    right_fit = np.array([np.mean(mov_avg_right[::-1][:,0][0:MOV_AVG_LENGTH]),\n",
    "                             np.mean(mov_avg_right[::-1][:,1][0:MOV_AVG_LENGTH]),\n",
    "                             np.mean(mov_avg_right[::-1][:,2][0:MOV_AVG_LENGTH])])\n",
    "\n",
    "    if mov_avg_left.shape[0] > 1000:\n",
    "      \n",
    "      mov_avg_left = mov_avg_left[0:MOV_AVG_LENGTH]\n",
    "    if mov_avg_right.shape[0] > 1000:\n",
    "      mov_avg_right = mov_avg_right[0:MOV_AVG_LENGTH]\n",
    "    final = draw_lines(img, transformedImage, left_fit, right_fit, perspective=[srcPoints, dstPoints])\n",
    "    final = overlayImage(final, transformedImage, 20, 20, 30)\n",
    "    # ------------------------------ to here ----------------------------------\n",
    "\n",
    "    # CALCULATIONS \n",
    "    distance_from_center = calculare_center_distance(final, left_fit, right_fit)\n",
    "    radius_of_lane = calc_radius(final, left_fit, right_fit)\n",
    "    finalResultImage = draw_text_on_photo(final, (\n",
    "      str(distance_from_center)+\"[m] from center \\n\"+\n",
    "      \"Radius:\"+\" \"+str(radius_of_lane)+\"[m]\"\n",
    "      )\n",
    "    )\n",
    "    \n",
    "    finalVid.append_data(finalResultImage)\n",
    "    # planVideo.append_data(transformedImage)\n",
    "    # plotImage(greyImg)\n",
    "finalVid.close()\n",
    "# planVideo.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
